{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.init as init\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, utils\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PreprocessData:\n",
    "    def __init__(self, csv):\n",
    "        houses = pd.read_csv(csv)\n",
    "        self.training_set = houses.sample(frac=0.75)\n",
    "        self.validate_set = houses.sample(frac=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HousePriceDataset(Dataset):\n",
    "    def __init__(self, df, exclude=[]):\n",
    "        houses = df.drop(exclude, axis=1)\n",
    "        self.houses = houses\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.houses)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.houses.iloc[idx, :].values\n",
    "    \n",
    "    def get_labels(self):\n",
    "        return list(self.houses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11276, 15)\n",
      "(3759, 15)\n"
     ]
    }
   ],
   "source": [
    "exclude_fields = ['date', 'id', 'zipcode', 'lat', 'long', 'condition']\n",
    "\n",
    "data = PreprocessData('./train.csv')\n",
    "data.training_set\n",
    "data.validate_set\n",
    "\n",
    "train_df = HousePriceDataset(data.training_set, exclude_fields)\n",
    "validate_df = HousePriceDataset(data.validate_set, exclude_fields)\n",
    "\n",
    "print(train_df.houses.shape)\n",
    "print(validate_df.houses.shape)\n",
    "train_generator = DataLoader( \\\n",
    "    train_df, batch_size=50, shuffle=True, num_workers=1)\n",
    "validate_generator = DataLoader( \\\n",
    "    validate_df, batch_size=50, shuffle=True, num_workers=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class OneLayerNet(nn.Module):\n",
    "    def __init__(self, D_in, D_out):\n",
    "        super(OneLayerNet, self).__init__()\n",
    "        self.linear1 = nn.Linear(D_in, D_out)\n",
    "\n",
    "    def forward(self, x):\n",
    "        y_pred = self.linear1(x)\n",
    "        return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TwoLayerNet(nn.Module):\n",
    "    def __init__(self, D_in, H, D_out):\n",
    "        super(TwoLayerNet, self).__init__()\n",
    "        self.linear1 = nn.Linear(D_in, H)\n",
    "        self.linear2 = nn.Linear(H, D_out)\n",
    "\n",
    "    def forward(self, x):\n",
    "        h_relu = self.linear1(x).clamp(min=0)\n",
    "        y_pred = self.linear2(h_relu)\n",
    "        return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FourLayerNet(nn.Module):\n",
    "    def __init__(self, D_in, H, D_out):\n",
    "        super(FourLayerNet, self).__init__()\n",
    "        self.linear1 = nn.Sequential(nn.Linear(D_in, H, bias=False), nn.BatchNorm1d(H))\n",
    "        self.linear2 = nn.Sequential(nn.Linear(H, H, bias=False), nn.BatchNorm1d(H))\n",
    "        self.linear3 = nn.Sequential(nn.Linear(H, H, bias=False), nn.BatchNorm1d(H))\n",
    "        self.linear4 = nn.Linear(H, D_out)\n",
    "\n",
    "    def forward(self, x):\n",
    "        h_relu = self.linear1(x).clamp(min=0)\n",
    "        h_relu2 = self.linear2(h_relu).clamp(min=0)\n",
    "        h_relu3 = self.linear3(h_relu2).clamp(min=0)\n",
    "        y_pred = self.linear4(h_relu3)\n",
    "        return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weight_init(m):\n",
    "    '''\n",
    "    Usage:\n",
    "        model = Model()\n",
    "        model.apply(weight_init)\n",
    "    '''\n",
    "    if isinstance(m, nn.Conv2d):\n",
    "        init.xavier_normal_(m.weight.data)\n",
    "        if m.bias is not None:\n",
    "            init.zeros_(m.bias.data)\n",
    "    elif isinstance(m, nn.Linear):\n",
    "        init.xavier_normal_(m.weight.data)\n",
    "        if m.bias is not None:\n",
    "            init.zeros_(m.bias.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "D_in, H, D_out = 14,100,1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = FourLayerNet(D_in, H, D_out)\n",
    "model.apply(weight_init)\n",
    "# criterion = nn.MSELoss(reduction='mean')\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_loss(model, loader):\n",
    "    loss = 0.\n",
    "    totals = 0\n",
    "    for (data, target) in loader:\n",
    "        totals += len(data)\n",
    "        loss += F.mse_loss(model(data), target, reduction='sum').item()\n",
    "    return loss/totals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN 0:  19218865.689024977\n",
      "VALIDATE 0:  15006766.80527422\n",
      "------------------------------------------------------------\n",
      "TRAIN 1:  10921074.11765779\n",
      "VALIDATE 1:  7446403.889914211\n",
      "------------------------------------------------------------\n",
      "TRAIN 2:  6991562.016812316\n",
      "VALIDATE 2:  6827187.076483644\n",
      "------------------------------------------------------------\n",
      "TRAIN 3:  6674345.683066778\n",
      "VALIDATE 3:  6786339.643934647\n",
      "------------------------------------------------------------\n",
      "TRAIN 4:  6677652.575598518\n",
      "VALIDATE 4:  6782960.210269778\n",
      "------------------------------------------------------------\n",
      "TRAIN 5:  6687353.805095685\n",
      "VALIDATE 5:  6787023.587603136\n",
      "------------------------------------------------------------\n",
      "TRAIN 6:  6684042.995003664\n",
      "VALIDATE 6:  6790653.494804022\n",
      "------------------------------------------------------------\n",
      "TRAIN 7:  6684641.893705467\n",
      "VALIDATE 7:  6790719.460039542\n",
      "------------------------------------------------------------\n",
      "TRAIN 8:  6680581.994161083\n",
      "VALIDATE 8:  6791738.767616613\n",
      "------------------------------------------------------------\n",
      "TRAIN 9:  6683283.061958697\n",
      "VALIDATE 9:  6792792.842433957\n",
      "------------------------------------------------------------\n",
      "TRAIN 10:  6681673.300655994\n",
      "VALIDATE 10:  6798319.209934829\n",
      "------------------------------------------------------------\n",
      "TRAIN 11:  6676838.199178307\n",
      "VALIDATE 11:  6791401.846639621\n",
      "------------------------------------------------------------\n",
      "TRAIN 12:  6680130.064228529\n",
      "VALIDATE 12:  6815301.913775161\n",
      "------------------------------------------------------------\n",
      "TRAIN 13:  6679215.089234639\n",
      "VALIDATE 13:  6780342.612816839\n",
      "------------------------------------------------------------\n",
      "TRAIN 14:  6677660.7931015305\n",
      "VALIDATE 14:  6797058.240179656\n",
      "------------------------------------------------------------\n",
      "TRAIN 15:  6684438.479260651\n",
      "VALIDATE 15:  6819258.508120465\n",
      "------------------------------------------------------------\n",
      "TRAIN 16:  6655370.649538973\n",
      "VALIDATE 16:  6806333.858604879\n",
      "------------------------------------------------------------\n",
      "TRAIN 17:  6686166.682597483\n",
      "VALIDATE 17:  6788253.162493547\n",
      "------------------------------------------------------------\n",
      "TRAIN 18:  6682118.878873835\n",
      "VALIDATE 18:  6808641.973760953\n",
      "------------------------------------------------------------\n",
      "TRAIN 19:  6683984.132284163\n",
      "VALIDATE 19:  6813264.339944299\n",
      "------------------------------------------------------------\n",
      "TRAIN 20:  6683469.314945226\n",
      "VALIDATE 20:  6796919.528345301\n",
      "------------------------------------------------------------\n",
      "TRAIN 21:  6684327.094377343\n",
      "VALIDATE 21:  6813077.112849979\n",
      "------------------------------------------------------------\n",
      "TRAIN 22:  6683227.693128649\n",
      "VALIDATE 22:  6801769.178258286\n",
      "------------------------------------------------------------\n",
      "TRAIN 23:  6685987.327187774\n",
      "VALIDATE 23:  6743162.908243766\n",
      "------------------------------------------------------------\n",
      "TRAIN 24:  6685018.110610934\n",
      "VALIDATE 24:  6818639.803997029\n",
      "------------------------------------------------------------\n",
      "TRAIN 25:  6678472.730903702\n",
      "VALIDATE 25:  6815637.489128436\n",
      "------------------------------------------------------------\n",
      "TRAIN 26:  6683644.411328613\n",
      "VALIDATE 26:  6936747.598493045\n",
      "------------------------------------------------------------\n",
      "TRAIN 27:  6685219.486302625\n",
      "VALIDATE 27:  6822602.70653538\n",
      "------------------------------------------------------------\n",
      "TRAIN 28:  6683336.5192484595\n",
      "VALIDATE 28:  6944925.141589673\n",
      "------------------------------------------------------------\n",
      "TRAIN 29:  6682236.161671674\n",
      "VALIDATE 29:  6848446.097319193\n",
      "------------------------------------------------------------\n",
      "TRAIN 30:  6681028.266098061\n",
      "VALIDATE 30:  6918253.673545824\n",
      "------------------------------------------------------------\n",
      "TRAIN 31:  6668685.673656893\n",
      "VALIDATE 31:  7062803.786733203\n",
      "------------------------------------------------------------\n",
      "TRAIN 32:  6681418.976897861\n",
      "VALIDATE 32:  6978280.225177164\n",
      "------------------------------------------------------------\n",
      "TRAIN 33:  6641708.126069965\n",
      "VALIDATE 33:  6996450.0763303945\n",
      "------------------------------------------------------------\n",
      "TRAIN 34:  6679945.534938767\n",
      "VALIDATE 34:  6887162.950428535\n",
      "------------------------------------------------------------\n",
      "TRAIN 35:  6683408.646324172\n",
      "VALIDATE 35:  7063300.4358012825\n",
      "------------------------------------------------------------\n",
      "TRAIN 36:  6685391.130456905\n",
      "VALIDATE 36:  6830848.53810914\n",
      "------------------------------------------------------------\n",
      "TRAIN 37:  6670565.836263116\n",
      "VALIDATE 37:  7086812.1372982\n",
      "------------------------------------------------------------\n",
      "TRAIN 38:  6682366.79958576\n",
      "VALIDATE 38:  6867660.763169779\n",
      "------------------------------------------------------------\n",
      "TRAIN 39:  6681077.493746922\n",
      "VALIDATE 39:  6942525.027279238\n",
      "------------------------------------------------------------\n",
      "TRAIN 40:  6681868.736028878\n",
      "VALIDATE 40:  7448467.748580145\n",
      "------------------------------------------------------------\n",
      "TRAIN 41:  6679318.334356115\n",
      "VALIDATE 41:  8347027.285547995\n",
      "------------------------------------------------------------\n",
      "TRAIN 42:  6685053.310812538\n",
      "VALIDATE 42:  7035956.599151758\n",
      "------------------------------------------------------------\n",
      "TRAIN 43:  6670036.275253761\n",
      "VALIDATE 43:  7042149.608050005\n",
      "------------------------------------------------------------\n",
      "TRAIN 44:  6680808.989848928\n",
      "VALIDATE 44:  7215427.466692477\n",
      "------------------------------------------------------------\n",
      "TRAIN 45:  6681884.3884155685\n",
      "VALIDATE 45:  6894793.505765576\n",
      "------------------------------------------------------------\n",
      "TRAIN 46:  6680180.5833480805\n",
      "VALIDATE 46:  6882370.504674034\n",
      "------------------------------------------------------------\n",
      "TRAIN 47:  6676386.777353171\n",
      "VALIDATE 47:  9058532.911163386\n",
      "------------------------------------------------------------\n",
      "TRAIN 48:  6679890.060469988\n",
      "VALIDATE 48:  7641817.138402919\n",
      "------------------------------------------------------------\n",
      "TRAIN 49:  6678207.824674054\n",
      "VALIDATE 49:  7063696.272264956\n",
      "------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for t in range(50):\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    train_totals = 0\n",
    "    for _, data in enumerate(train_generator):\n",
    "        x, y = data[:,1:].float(), data[:, 0].float()\n",
    "        train_totals += len(data)\n",
    "        loss = F.mse_loss(model(x), y, reduction=\"sum\")\n",
    "        train_loss += loss.item()\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    train_loss = train_loss/train_totals * 1e-6\n",
    "    \n",
    "    print(\"TRAIN \" + str(t) + \": \", train_loss)\n",
    "    \n",
    "    model.eval()\n",
    "    valid_loss = 0\n",
    "    valid_totals = 0\n",
    "    for _, data in enumerate(validate_generator):\n",
    "        x, y = data[:,1:].float(), data[:, 0].float()\n",
    "        valid_totals += len(data)\n",
    "        loss = F.mse_loss(model(x), y, reduction=\"sum\")\n",
    "        valid_loss += loss.item()\n",
    "    valid_loss = valid_loss/valid_totals * 1e-6\n",
    "    \n",
    "    print(\"VALIDATE \" + str(t) + \": \", valid_loss)\n",
    "        \n",
    "    print(\"------------------------------------------------------------\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 46653.546875\n",
      "1 114894.890625\n",
      "2 194340.78125\n",
      "3 84300.9609375\n",
      "4 82674.2890625\n",
      "5 50256.91796875\n",
      "6 93193.2421875\n",
      "7 52049.9609375\n",
      "8 29042.482421875\n",
      "9 46815.1640625\n",
      "10 135198.390625\n",
      "11 92232.90625\n",
      "12 433154.9375\n",
      "13 38341.39453125\n",
      "14 507893.25\n",
      "15 69008.5234375\n",
      "16 78224.359375\n",
      "17 835537.875\n",
      "18 36253.546875\n",
      "19 77298.671875\n"
     ]
    }
   ],
   "source": [
    "for t in range(20):\n",
    "    model.eval()\n",
    "    for _, data in enumerate(validate_generator):\n",
    "        x, y = data[:,1:].float(), data[:, 0].float()\n",
    "        y_pred = model(x)\n",
    "        loss = criterion(y_pred, y)*1e-6\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    print(t, loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
